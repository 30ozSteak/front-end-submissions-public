### Student:
Hugh Morrison

### Project Name:  
Aggro surf

#### Check In: 1  

#### Collaborators:  
N/A

#### Project Pitch  
The kind folks at Ocearch (Shark Non Profit) have not gotten back to me and so I think I'm going to go back to the drawing board. I'd like to make a sort of aggregate surf forecast site that pulls in various surf related APIs and then displays the data in a meaningful way. Individual surf forecasting sites are notoriously inaccurate and so this would not only be a useful implementation for surfers around the world, but also a mega sweet way to learn D3.. I foresee it using redux/react/react-router/D3. I also plan to learn web scraping using node.js.

This would pull data from Surfline, MagicSeaweed & Spitcast APIs to display an aggregated surf forecast.

And then maybe, if I am successful at doing all that, and the shark people get back to me, I could pull in the shark data and implement a, "don't swim here as you may get eaten" alert.


### Deliverables  

#### APIs:  
This would pull data from Surfline, MagicSeaweed & Spitcast APIs to display an aggregated surf forecast.

surfline.com , magicseaweed.com , spitcast.com

I have yet to find the documentation I need.

#### Wireframes  
![welcome](http://g.recordit.co/zddNJYYDQz.gif)

![graph](http://g.recordit.co/qp8fpV3enM.gif)

![detail wireframe](http://g.recordit.co/9VTO1fqQ4l.gif)

#### Waffle.io
![yung waffle](http://g.recordit.co/RZ3R4F79K8.gif)

* [LINK TO WAFFLE](https://waffle.io/hmorri32/aggro-surf)

### Reflection  

#### Order Of Attack  
I plan on starting with the welcome page. Ideally, that center graphic will be animated. Next, I will probably tackle the detail screen, as I foresee the chart portion to be the most difficult. The chart section is visibly gigantic and so I plan on doing something with CSS and overflow to make the charts scrollable if they do in fact overflow.


#### Nice To Haves   
API keys... Very cool animations, illustrations, and visuals.

#### Biggest Challenges  
I predict that acquiring the necessary api information will be problematic. I then foresee myself being forced to learn how to scrape the web. The entire project will then become a cascading problem. I hope to prevent this.

Next, I foresee visually representing my data to be problematic. To combat this difficulty, I will use D3's extensive documentation and will reach out to Turing students/mentors who are more familiar with the technology than I. I am also prepared to pivot. 

